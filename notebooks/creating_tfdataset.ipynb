{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d0cf3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import requests\n",
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f802d5c3",
   "metadata": {},
   "source": [
    "# Loading in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ecac700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_in_memory():\n",
    "    \"\"\"\n",
    "    Load dataset from hugging face servers in memory\n",
    "    \"\"\"\n",
    "    url = \"https://datasets-server.huggingface.co/parquet?dataset=aadityaubhat%2FGPT-wiki-intro\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code !=200:\n",
    "        return f\"error during dataset request: {response.status_code}\"\n",
    "    \n",
    "    url_parquet = [files['url'] for files in response.json()['parquet_files']]\n",
    "    \n",
    "    \n",
    "    df = [pd.read_parquet(url_) for url_ in url_parquet]\n",
    "    \n",
    "    return pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa0ef8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds(path_data):\n",
    "    \"\"\"\n",
    "    Load dataset and basic transformation for our task\n",
    "    \"\"\"\n",
    "    if 'data.csv' in os.listdir(path_data):\n",
    "        print('Loading dataset from local...')\n",
    "        df = pd.read_csv(os.path.join(path_data,'data.csv'),index_col='id')\n",
    "    else:\n",
    "        df = load_data_in_memory()\n",
    "        df.set_index('id',inplace=True)\n",
    "        df['random']=np.random.random(len(df))\n",
    "\n",
    "        # reorganize ds and randomize samples wiki/generated\n",
    "        df.loc[df['random']<.5,'text']=df['generated_intro']\n",
    "        df.loc[df['random']<.5,'label']='generated'\n",
    "        df.loc[df['random']>=.5,'text']=df['wiki_intro']\n",
    "        df.loc[df['random']>=.5,'label']='wiki'\n",
    "        # dump csv\n",
    "        df.to_csv(os.path.join(path_data,'data.csv'))\n",
    "        \n",
    "    df['label']=df['label'].replace({'generated':1,'wiki':0})\n",
    "    \n",
    "    display(df.head())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f466ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from local...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>wiki_intro</th>\n",
       "      <th>generated_intro</th>\n",
       "      <th>title_len</th>\n",
       "      <th>wiki_intro_len</th>\n",
       "      <th>generated_intro_len</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>generated_text_tokens</th>\n",
       "      <th>random</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63064638</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Sexhow%20railway...</td>\n",
       "      <td>Sexhow railway station</td>\n",
       "      <td>Sexhow railway station was a railway station b...</td>\n",
       "      <td>Sexhow railway station was a railway station l...</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>78</td>\n",
       "      <td>200 word wikipedia style introduction on 'Sexh...</td>\n",
       "      <td>located in the town of Sexhow, on the Cumbria...</td>\n",
       "      <td>25</td>\n",
       "      <td>88</td>\n",
       "      <td>0.170068</td>\n",
       "      <td>Sexhow railway station was a railway station l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279621</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Eti%C3%A4inen</td>\n",
       "      <td>Etiäinen</td>\n",
       "      <td>In Finnish folklore, all places and things, an...</td>\n",
       "      <td>In Finnish folklore, all places and things, an...</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>80</td>\n",
       "      <td>200 word wikipedia style introduction on 'Etiä...</td>\n",
       "      <td>animate or inanimate, have a spirit or \"etiäi...</td>\n",
       "      <td>26</td>\n",
       "      <td>101</td>\n",
       "      <td>0.839452</td>\n",
       "      <td>In Finnish folklore, all places and things, an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287229</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Inverse%20functi...</td>\n",
       "      <td>Inverse function theorem</td>\n",
       "      <td>In mathematics, specifically differential calc...</td>\n",
       "      <td>In mathematics, specifically differential calc...</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>59</td>\n",
       "      <td>200 word wikipedia style introduction on 'Inve...</td>\n",
       "      <td>function theorem states that for every real-v...</td>\n",
       "      <td>26</td>\n",
       "      <td>65</td>\n",
       "      <td>0.532203</td>\n",
       "      <td>In mathematics, specifically differential calc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26712375</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Stepping%20on%20...</td>\n",
       "      <td>Stepping on Roses</td>\n",
       "      <td>is a Japanese shōjo manga series written and i...</td>\n",
       "      <td>is a Japanese shōjo manga series written and i...</td>\n",
       "      <td>3</td>\n",
       "      <td>335</td>\n",
       "      <td>121</td>\n",
       "      <td>200 word wikipedia style introduction on 'Step...</td>\n",
       "      <td>and illustrated by Maki Fujii. The series fol...</td>\n",
       "      <td>26</td>\n",
       "      <td>150</td>\n",
       "      <td>0.715507</td>\n",
       "      <td>is a Japanese shōjo manga series written and i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38894426</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Rob%20Bradley</td>\n",
       "      <td>Rob Bradley</td>\n",
       "      <td>Robert Milner \"Rob\" Bradley, Jr. (born August ...</td>\n",
       "      <td>Robert Milner \"Rob\" Bradley, Jr. (born August ...</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "      <td>136</td>\n",
       "      <td>200 word wikipedia style introduction on 'Rob ...</td>\n",
       "      <td>29, 1973) is an American former professional ...</td>\n",
       "      <td>28</td>\n",
       "      <td>162</td>\n",
       "      <td>0.395063</td>\n",
       "      <td>Robert Milner \"Rob\" Bradley, Jr. (born August ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        url  \\\n",
       "id                                                            \n",
       "63064638  https://en.wikipedia.org/wiki/Sexhow%20railway...   \n",
       "279621          https://en.wikipedia.org/wiki/Eti%C3%A4inen   \n",
       "287229    https://en.wikipedia.org/wiki/Inverse%20functi...   \n",
       "26712375  https://en.wikipedia.org/wiki/Stepping%20on%20...   \n",
       "38894426        https://en.wikipedia.org/wiki/Rob%20Bradley   \n",
       "\n",
       "                             title  \\\n",
       "id                                   \n",
       "63064638    Sexhow railway station   \n",
       "279621                    Etiäinen   \n",
       "287229    Inverse function theorem   \n",
       "26712375         Stepping on Roses   \n",
       "38894426               Rob Bradley   \n",
       "\n",
       "                                                 wiki_intro  \\\n",
       "id                                                            \n",
       "63064638  Sexhow railway station was a railway station b...   \n",
       "279621    In Finnish folklore, all places and things, an...   \n",
       "287229    In mathematics, specifically differential calc...   \n",
       "26712375  is a Japanese shōjo manga series written and i...   \n",
       "38894426  Robert Milner \"Rob\" Bradley, Jr. (born August ...   \n",
       "\n",
       "                                            generated_intro  title_len  \\\n",
       "id                                                                       \n",
       "63064638  Sexhow railway station was a railway station l...          3   \n",
       "279621    In Finnish folklore, all places and things, an...          1   \n",
       "287229    In mathematics, specifically differential calc...          3   \n",
       "26712375  is a Japanese shōjo manga series written and i...          3   \n",
       "38894426  Robert Milner \"Rob\" Bradley, Jr. (born August ...          2   \n",
       "\n",
       "          wiki_intro_len  generated_intro_len  \\\n",
       "id                                              \n",
       "63064638             174                   78   \n",
       "279621               187                   80   \n",
       "287229               170                   59   \n",
       "26712375             335                  121   \n",
       "38894426             170                  136   \n",
       "\n",
       "                                                     prompt  \\\n",
       "id                                                            \n",
       "63064638  200 word wikipedia style introduction on 'Sexh...   \n",
       "279621    200 word wikipedia style introduction on 'Etiä...   \n",
       "287229    200 word wikipedia style introduction on 'Inve...   \n",
       "26712375  200 word wikipedia style introduction on 'Step...   \n",
       "38894426  200 word wikipedia style introduction on 'Rob ...   \n",
       "\n",
       "                                             generated_text  prompt_tokens  \\\n",
       "id                                                                           \n",
       "63064638   located in the town of Sexhow, on the Cumbria...             25   \n",
       "279621     animate or inanimate, have a spirit or \"etiäi...             26   \n",
       "287229     function theorem states that for every real-v...             26   \n",
       "26712375   and illustrated by Maki Fujii. The series fol...             26   \n",
       "38894426   29, 1973) is an American former professional ...             28   \n",
       "\n",
       "          generated_text_tokens    random  \\\n",
       "id                                          \n",
       "63064638                     88  0.170068   \n",
       "279621                      101  0.839452   \n",
       "287229                       65  0.532203   \n",
       "26712375                    150  0.715507   \n",
       "38894426                    162  0.395063   \n",
       "\n",
       "                                                       text  label  \n",
       "id                                                                  \n",
       "63064638  Sexhow railway station was a railway station l...      1  \n",
       "279621    In Finnish folklore, all places and things, an...      0  \n",
       "287229    In mathematics, specifically differential calc...      0  \n",
       "26712375  is a Japanese shōjo manga series written and i...      0  \n",
       "38894426  Robert Milner \"Rob\" Bradley, Jr. (born August ...      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH_DATA = os.path.join(os.path.dirname(os.path.abspath(os.path.curdir)),'raw_data')\n",
    "\n",
    "df = get_ds(PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a16ca42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute # sentences\n",
    "df['nsentences'] = df['text'].apply(lambda x : len(x.split('.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9e6e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_per_sentence(text):\n",
    "    \"\"\"\n",
    "    Compute the mean and variance of the number of words per sentences of a text.\n",
    "    \"\"\"\n",
    "    sentences = text.split('.')\n",
    "    lengths = []\n",
    "    for s in sentences : \n",
    "        lengths.append(len(s.split()))\n",
    "    return [np.mean(np.array(lengths)),np.std(np.array(lengths))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a121a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e = pd.concat([\n",
    "    df,\n",
    "    df['text'].apply(word_per_sentence)\\\n",
    "                .apply(pd.Series)\\\n",
    "                .rename({0:'mean_w_p_s',1:'var_w_p_s'},axis=1)]\n",
    "                 ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "279eaf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_e[['text','nsentences','mean_w_p_s','var_w_p_s']]\n",
    "y = df_e[['label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e12d4e",
   "metadata": {},
   "source": [
    "# Serialize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f0f885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.train.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _nonscaler_feature(value):\n",
    "    serialized_nonscalar = tf.io.serialize_tensor(value)\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[serialized_nonscalar.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4105c65a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(_bytes_feature(b'test_string'))\n",
    "print(_bytes_feature(u'test_bytes'.encode('utf-8')))\n",
    "\n",
    "print(_float_feature(np.exp(1)))\n",
    "\n",
    "print(_nonscaler_feature([1,2,3]))\n",
    "\n",
    "print(_int64_feature(True))\n",
    "print(_int64_feature(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "384dbb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(id_,text,vect, nsentences, mean_w_p_s ,var_w_p_s, label):\n",
    "    \"\"\"\n",
    "    Creates a tf.train.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
    "    # data type.\n",
    "    feature = {\n",
    "        'id': _int64_feature(int(id_)),\n",
    "        'text': _bytes_feature(text),\n",
    "        'vect':_nonscaler_feature(vect),\n",
    "        'nsentences': _int64_feature(int(nsentences)),\n",
    "        'mean_w_p_s': _float_feature(float(mean_w_p_s)),\n",
    "        'var_w_p_s': _float_feature(float(var_w_p_s)),\n",
    "        'label': _int64_feature(int(label)),\n",
    "    }\n",
    "\n",
    "    # Create a Features message using tf.train.Example.\n",
    "\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989591c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8be6e809",
   "metadata": {},
   "source": [
    "# add word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ddca2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = gensim.downloader.load('glove-wiki-gigaword-100')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d7a44f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.5 ms, sys: 536 µs, total: 29 ms\n",
      "Wall time: 28.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(20000):\n",
    "    if 'hello' in wv: \n",
    "        wv.get_vector('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "47d2bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.97 s, sys: 9.45 ms, total: 1.98 s\n",
      "Wall time: 1.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(20000):\n",
    "    if 'hello' in wv.index_to_key: \n",
    "        wv.get_vector('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d912ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence_pretrained(w2v, sentence):\n",
    "    \"\"\"\n",
    "    Embed a sentence given a trained Word2Vec\n",
    "    \"\"\"\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in w2v:\n",
    "            embedded_sentence.append(w2v.get_vector(word))\n",
    "\n",
    "    return np.array(embedded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4f9bd459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n",
      "50.00%\n"
     ]
    }
   ],
   "source": [
    "sentences = X.text[:100]  \n",
    "LEN=len(sentences)\n",
    "vect=[]\n",
    "for i,x in enumerate(sentences):\n",
    "    vect.append(embed_sentence_pretrained(wv,x))\n",
    "    if i%50==0:\n",
    "        print(f'{i*100/LEN:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "baf020b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_pad=tf.keras.utils.pad_sequences(vect,truncating='post',padding='post',maxlen=256,dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d5ec14",
   "metadata": {},
   "source": [
    "## full ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3928e134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5a1dfeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#useless - for tf.dataset usecase\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((X[:100].index,\n",
    "                                        X[:100].text,\n",
    "                                         vect_pad,\n",
    "                                         X[:100].nsentences,\n",
    "                                         X[:100].mean_w_p_s,\n",
    "                                         X[:100].var_w_p_s,\n",
    "                                         y[:100].label))\n",
    "\n",
    "def tf_serialize_example(f0,f1,f2,f3,y):\n",
    "    tf_string = tf.py_function(\n",
    "    serialize_example,\n",
    "    (f0, f1, f2, f3,y),  # Pass these args to the above function.\n",
    "    tf.string)      # The return type is `tf.string`.\n",
    "    return tf.reshape(tf_string, ()) # The result is a scalar.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generator():\n",
    "    for features in ds:\n",
    "        yield serialize_example(*features)\n",
    "\n",
    "serialized_features_dataset = tf.data.Dataset.from_generator(\n",
    "    generator, output_types=tf.string, output_shapes=())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d479ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pur python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "15943d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter('hey.tfrecord') as writer:\n",
    "    for i in range(100):\n",
    "        example = serialize_example(\n",
    "            X.index[i],\n",
    "#             X.reset_index().id[i],\n",
    "            X.text.str.encode('utf-8').iloc[i],\n",
    "            vect_pad[i],\n",
    "            X.nsentences.iloc[i],\n",
    "            X.mean_w_p_s.iloc[i],\n",
    "            X.var_w_p_s.iloc[i],\n",
    "            y.label.iloc[i])\n",
    "        writer.write(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "60b089e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test reading\n",
    "filenames = ['hey.tfrecord']\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0369caa0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a=0\n",
    "for i in raw_dataset:\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(i.numpy())\n",
    "    a+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e972535f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8588ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'id': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'text': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'vect': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'nsentences': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'mean_w_p_s': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "    'var_w_p_s': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input `tf.train.Example` proto using the dictionary above.\n",
    "    parsed_ex = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    label = parsed_ex.pop('label')\n",
    "    vect = parsed_ex.pop('vect')\n",
    "    parsed_ex['vect'] = tf.io.parse_tensor(vect,tf.double)\n",
    "    return parsed_ex,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "08f46897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=({'id': TensorSpec(shape=(), dtype=tf.int64, name=None), 'mean_w_p_s': TensorSpec(shape=(), dtype=tf.float32, name=None), 'nsentences': TensorSpec(shape=(), dtype=tf.int64, name=None), 'text': TensorSpec(shape=(), dtype=tf.string, name=None), 'var_w_p_s': TensorSpec(shape=(), dtype=tf.float32, name=None), 'vect': TensorSpec(shape=<unknown>, dtype=tf.float64, name=None)}, TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "8037a6bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': <tf.Tensor: shape=(), dtype=int64, numpy=63064638>,\n",
       "  'mean_w_p_s': <tf.Tensor: shape=(), dtype=float32, numpy=13.0>,\n",
       "  'nsentences': <tf.Tensor: shape=(), dtype=int64, numpy=6>,\n",
       "  'text': <tf.Tensor: shape=(), dtype=string, numpy=b'Sexhow railway station was a railway station located in the town of Sexhow, on the Cumbrian Coast Line in North West England. The station was opened by the Lancashire and Yorkshire Railway on 7 October 1870. It was closed to passengers on 5 January 1950, and to goods on 12 May 1965. \\n\\nThe station building is now a private residence. There is a small amount of trackage remaining near the building, used currently by a local agricultural business.'>,\n",
       "  'var_w_p_s': <tf.Tensor: shape=(), dtype=float32, numpy=7.187953>,\n",
       "  'vect': <tf.Tensor: shape=(256, 100), dtype=float64, numpy=\n",
       "  array([[-0.52605999, -0.066991  , -0.17351   , ..., -0.79123002,\n",
       "           0.047581  ,  0.084428  ],\n",
       "         [-0.67211998,  1.14579999,  0.12519   , ..., -0.57916999,\n",
       "           0.41294   , -0.71662003],\n",
       "         [-0.20314001,  0.50467002, -0.25222999, ..., -0.34617999,\n",
       "          -0.18627   , -0.31606001],\n",
       "         ...,\n",
       "         [-0.11752   ,  0.97272003, -0.29021001, ..., -0.50598001,\n",
       "          -0.28476   , -0.70045   ],\n",
       "         [-0.52605999, -0.066991  , -0.17351   , ..., -0.79123002,\n",
       "           0.047581  ,  0.084428  ],\n",
       "         [-0.33978999,  0.20941   ,  0.46348   , ..., -0.23394001,\n",
       "           0.47297999, -0.028803  ]])>},\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=1>)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(parsed_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8170356d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

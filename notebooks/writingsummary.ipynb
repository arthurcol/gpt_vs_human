{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "165fe2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fe234470",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(os.path.abspath(os.path.pardir),'logs','simple_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f302aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wr = tf.summary.create_file_writer(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c559de11",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_ResourceSummaryWriter' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m wr:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(w\u001b[38;5;241m.\u001b[39mvalue)\n",
      "\u001b[0;31mTypeError\u001b[0m: '_ResourceSummaryWriter' object is not iterable"
     ]
    }
   ],
   "source": [
    "for w in wr:\n",
    "    print(w.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9d55486f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.summary_ops_v2._ResourceSummaryWriter at 0x17fe58ac0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e3409d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\t\\x89$XN\\x84\\xfd\\xd8A*\\'\\n%\\n\\nepoch_lossB\\n\\x08\\x01\\x12\\x00\"\\x04\\xa7\\x84\\x0f?J\\x0b\\n\\t\\n\\x07scalars'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7d734d04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Could not create converter for input encoding: lation- [Op:UnicodeDecode]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rec \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mTFRecordDataset([log_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/train/events.out.tfevents.1677070482.MacBook-Pro-de-Arthur.local.93433.3.v2\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43municode_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlation-\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gpt-vs-human-7LNN4CJ4-py3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gpt-vs-human-7LNN4CJ4-py3.10/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7163\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7164\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Could not create converter for input encoding: lation- [Op:UnicodeDecode]"
     ]
    }
   ],
   "source": [
    "for rec in tf.data.TFRecordDataset([log_dir+'/train/events.out.tfevents.1677070482.MacBook-Pro-de-Arthur.local.93433.3.v2']):\n",
    "    print(tf.strings.unicode_decode(rec,'lation-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c9dca2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaa'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b'aaa'.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "029653fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.core.util.event_pb2 import Event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39f3b0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirr = [log_dir+'/train/events.out.tfevents.1677070482.MacBook-Pro-de-Arthur.local.93433.3.v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "43563e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fafdee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6b8f16e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Message.HasExtension() missing 1 required positional argument: 'extension_handle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ev\u001b[38;5;241m.\u001b[39msummary:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# Iterate summary values\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m ev\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[0;32m---> 13\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHasExtension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#             #Check if the tag should be renamed\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#             if v.tag in old_tags:\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#                 # Rename with new tag name\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#                 v.tag = new_tag\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Message.HasExtension() missing 1 required positional argument: 'extension_handle'"
     ]
    }
   ],
   "source": [
    "for rec in tf.data.TFRecordDataset([log_dir+'/train/events.out.tfevents.1677070482.MacBook-Pro-de-Arthur.local.93433.3.v2']):\n",
    "\n",
    "    # Read event\n",
    "    ev = Event()\n",
    "    ev.MergeFromString(rec.numpy())\n",
    "    # Check if it is a summary\n",
    "\n",
    "#     print(ev.summary)\n",
    "#     print(rec)\n",
    "    if ev.summary:\n",
    "        # Iterate summary values\n",
    "        for v in ev.summary.value:\n",
    "            print(v.)\n",
    "\n",
    "#             #Check if the tag should be renamed\n",
    "#             if v.tag in old_tags:\n",
    "#                 # Rename with new tag name\n",
    "#                 v.tag = new_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6d19c3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tag: \"epoch_loss\"\n",
       "tensor {\n",
       "  dtype: DT_FLOAT\n",
       "  tensor_shape {\n",
       "  }\n",
       "  tensor_content: \"\\247\\204\\017?\"\n",
       "}\n",
       "metadata {\n",
       "  plugin_data {\n",
       "    plugin_name: \"scalars\"\n",
       "  }\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.summary.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1b5cc8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_events(input_path, output_path):\n",
    "    # Make a record writer\n",
    "#     with tf.io.TFRecordWriter(str(output_path)) as writer:\n",
    "    writer= tf.summary.create_file_writer(\"summaries\")\n",
    "    with writer.as_default():\n",
    "        # Iterate event records\n",
    "        for rec in tf.data.TFRecordDataset([str(input_path)]):\n",
    "            # Read event\n",
    "            ev = Event()\n",
    "            ev.MergeFromString(rec.numpy())\n",
    "            # Check if it is a summary\n",
    "            writer.write(ev.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d705af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempt = [log_dir+'/train/events.out.tfevents.1677068048.MacBook-Pro-de-Arthur.local.93433.0.v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0a928e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_events(input_path,outputname):\n",
    "    # Make a record writer\n",
    "#     with tf.io.TFRecordWriter(str(output_path)) as writer:\n",
    "    writer= tf.summary.create_file_writer(outputname)\n",
    "    with writer.as_default():\n",
    "        # Iterate event records\n",
    "        for i,rec in enumerate(tf.data.TFRecordDataset([str(input_path)])):\n",
    "            # Read event\n",
    "            ev = Event()\n",
    "            ev.MergeFromString(rec.numpy())\n",
    "            for v in ev.summary.value:\n",
    "#                 print(v.tensor,v.tag)\n",
    "                tf.summary.scalar(v.tag, tf.make_ndarray(v.tensor), step=i)\n",
    "        writer.flush()\n",
    "                # Check if it is a summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "93d05226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../logs/simple_lstm/train/events.out.tfevents.1677068048.MacBook-Pro-de-Arthur.local.93433.0.v2',\n",
       " '../logs/simple_lstm/train/events.out.tfevents.1677070482.MacBook-Pro-de-Arthur.local.93433.3.v2',\n",
       " '../logs/simple_lstm/train/events.out.tfevents.1677074838.MacBook-Pro-de-Arthur.local.93433.5.v2']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [os.path.join('../logs/simple_lstm/train/',f) for f in os.listdir('../logs/simple_lstm/train/')]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "030fcbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,o in zip(files,['v0','v3','v5']):\n",
    "    copy_events(i,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9c64804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_events(input_path,input_path_2,outputname):\n",
    "    # Make a record writer\n",
    "#     with tf.io.TFRecordWriter(str(output_path)) as writer:\n",
    "    writer= tf.summary.create_file_writer(outputname)\n",
    "    with writer.as_default():\n",
    "        epochs = 0\n",
    "        # Iterate event records\n",
    "\n",
    "        for i,rec in enumerate(tf.data.TFRecordDataset([str(input_path)])):\n",
    "            # Read event\n",
    "            ev = Event()\n",
    "            ev.MergeFromString(rec.numpy())\n",
    "            for v in ev.summary.value:\n",
    "#                 print(v.tensor,v.tag)\n",
    "                tf.summary.scalar(v.tag, tf.make_ndarray(v.tensor), step=i)\n",
    "            epochs=i\n",
    "        for i,rec in enumerate(tf.data.TFRecordDataset([str(input_path_2)])):\n",
    "            if epochs+i > 66:\n",
    "                print('breaking   ',epochs+i)\n",
    "                break\n",
    "            # Read event\n",
    "            ev = Event()\n",
    "            ev.MergeFromString(rec.numpy())\n",
    "            for v in ev.summary.value:\n",
    "#                 print(v.tensor,v.tag)\n",
    "                tf.summary.scalar(v.tag, tf.make_ndarray(v.tensor), step=epochs+i)\n",
    "        print('flushing')\n",
    "        writer.flush()\n",
    "                # Check if it is a summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b6eb121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_events(files[0],files[1],'miracle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "cec2f66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../logs/simple_lstm/validation/events.out.tfevents.1677068188.MacBook-Pro-de-Arthur.local.93433.1.v2',\n",
       " '../logs/simple_lstm/validation/events.out.tfevents.1677075128.MacBook-Pro-de-Arthur.local.93433.6.v2',\n",
       " '../logs/simple_lstm/validation/events.out.tfevents.1677070627.MacBook-Pro-de-Arthur.local.93433.4.v2']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_val = [os.path.join('../logs/simple_lstm/validation/',f) for f in os.listdir('../logs/simple_lstm/validation/')]\n",
    "files_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "17af84bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,o in zip(files_val,['v1','v6','v4']):\n",
    "    copy_events(i,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "eb2eae5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breaking    67\n",
      "flushing\n"
     ]
    }
   ],
   "source": [
    "concat_events(files_val[0],files_val[2],'miracle_val3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796534a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eec4886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69781ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a489b92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49ef6657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 12:30:12.209779: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-23 12:30:12.209843: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300de621",
   "metadata": {},
   "source": [
    "# get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ba805dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds():\n",
    "    url = \"https://datasets-server.huggingface.co/parquet?dataset=aadityaubhat%2FGPT-wiki-intro\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code !=200:\n",
    "        return f\"error during dataset request: {response.status_code}\"\n",
    "    \n",
    "    url_parquet = [files['url'] for files in response.json()['parquet_files']]\n",
    "    \n",
    "    \n",
    "    df = [pd.read_parquet(url_) for url_ in url_parquet]\n",
    "    \n",
    "    return pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1deee7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data.csv']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7ac858f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading local\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>wiki_intro</th>\n",
       "      <th>generated_intro</th>\n",
       "      <th>title_len</th>\n",
       "      <th>wiki_intro_len</th>\n",
       "      <th>generated_intro_len</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>generated_text_tokens</th>\n",
       "      <th>random</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63064638</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Sexhow%20railway...</td>\n",
       "      <td>Sexhow railway station</td>\n",
       "      <td>Sexhow railway station was a railway station b...</td>\n",
       "      <td>Sexhow railway station was a railway station l...</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>78</td>\n",
       "      <td>200 word wikipedia style introduction on 'Sexh...</td>\n",
       "      <td>located in the town of Sexhow, on the Cumbria...</td>\n",
       "      <td>25</td>\n",
       "      <td>88</td>\n",
       "      <td>0.170068</td>\n",
       "      <td>Sexhow railway station was a railway station l...</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279621</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Eti%C3%A4inen</td>\n",
       "      <td>Etiäinen</td>\n",
       "      <td>In Finnish folklore, all places and things, an...</td>\n",
       "      <td>In Finnish folklore, all places and things, an...</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>80</td>\n",
       "      <td>200 word wikipedia style introduction on 'Etiä...</td>\n",
       "      <td>animate or inanimate, have a spirit or \"etiäi...</td>\n",
       "      <td>26</td>\n",
       "      <td>101</td>\n",
       "      <td>0.839452</td>\n",
       "      <td>In Finnish folklore, all places and things, an...</td>\n",
       "      <td>wiki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287229</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Inverse%20functi...</td>\n",
       "      <td>Inverse function theorem</td>\n",
       "      <td>In mathematics, specifically differential calc...</td>\n",
       "      <td>In mathematics, specifically differential calc...</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>59</td>\n",
       "      <td>200 word wikipedia style introduction on 'Inve...</td>\n",
       "      <td>function theorem states that for every real-v...</td>\n",
       "      <td>26</td>\n",
       "      <td>65</td>\n",
       "      <td>0.532203</td>\n",
       "      <td>In mathematics, specifically differential calc...</td>\n",
       "      <td>wiki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26712375</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Stepping%20on%20...</td>\n",
       "      <td>Stepping on Roses</td>\n",
       "      <td>is a Japanese shōjo manga series written and i...</td>\n",
       "      <td>is a Japanese shōjo manga series written and i...</td>\n",
       "      <td>3</td>\n",
       "      <td>335</td>\n",
       "      <td>121</td>\n",
       "      <td>200 word wikipedia style introduction on 'Step...</td>\n",
       "      <td>and illustrated by Maki Fujii. The series fol...</td>\n",
       "      <td>26</td>\n",
       "      <td>150</td>\n",
       "      <td>0.715507</td>\n",
       "      <td>is a Japanese shōjo manga series written and i...</td>\n",
       "      <td>wiki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38894426</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Rob%20Bradley</td>\n",
       "      <td>Rob Bradley</td>\n",
       "      <td>Robert Milner \"Rob\" Bradley, Jr. (born August ...</td>\n",
       "      <td>Robert Milner \"Rob\" Bradley, Jr. (born August ...</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "      <td>136</td>\n",
       "      <td>200 word wikipedia style introduction on 'Rob ...</td>\n",
       "      <td>29, 1973) is an American former professional ...</td>\n",
       "      <td>28</td>\n",
       "      <td>162</td>\n",
       "      <td>0.395063</td>\n",
       "      <td>Robert Milner \"Rob\" Bradley, Jr. (born August ...</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        url  \\\n",
       "id                                                            \n",
       "63064638  https://en.wikipedia.org/wiki/Sexhow%20railway...   \n",
       "279621          https://en.wikipedia.org/wiki/Eti%C3%A4inen   \n",
       "287229    https://en.wikipedia.org/wiki/Inverse%20functi...   \n",
       "26712375  https://en.wikipedia.org/wiki/Stepping%20on%20...   \n",
       "38894426        https://en.wikipedia.org/wiki/Rob%20Bradley   \n",
       "\n",
       "                             title  \\\n",
       "id                                   \n",
       "63064638    Sexhow railway station   \n",
       "279621                    Etiäinen   \n",
       "287229    Inverse function theorem   \n",
       "26712375         Stepping on Roses   \n",
       "38894426               Rob Bradley   \n",
       "\n",
       "                                                 wiki_intro  \\\n",
       "id                                                            \n",
       "63064638  Sexhow railway station was a railway station b...   \n",
       "279621    In Finnish folklore, all places and things, an...   \n",
       "287229    In mathematics, specifically differential calc...   \n",
       "26712375  is a Japanese shōjo manga series written and i...   \n",
       "38894426  Robert Milner \"Rob\" Bradley, Jr. (born August ...   \n",
       "\n",
       "                                            generated_intro  title_len  \\\n",
       "id                                                                       \n",
       "63064638  Sexhow railway station was a railway station l...          3   \n",
       "279621    In Finnish folklore, all places and things, an...          1   \n",
       "287229    In mathematics, specifically differential calc...          3   \n",
       "26712375  is a Japanese shōjo manga series written and i...          3   \n",
       "38894426  Robert Milner \"Rob\" Bradley, Jr. (born August ...          2   \n",
       "\n",
       "          wiki_intro_len  generated_intro_len  \\\n",
       "id                                              \n",
       "63064638             174                   78   \n",
       "279621               187                   80   \n",
       "287229               170                   59   \n",
       "26712375             335                  121   \n",
       "38894426             170                  136   \n",
       "\n",
       "                                                     prompt  \\\n",
       "id                                                            \n",
       "63064638  200 word wikipedia style introduction on 'Sexh...   \n",
       "279621    200 word wikipedia style introduction on 'Etiä...   \n",
       "287229    200 word wikipedia style introduction on 'Inve...   \n",
       "26712375  200 word wikipedia style introduction on 'Step...   \n",
       "38894426  200 word wikipedia style introduction on 'Rob ...   \n",
       "\n",
       "                                             generated_text  prompt_tokens  \\\n",
       "id                                                                           \n",
       "63064638   located in the town of Sexhow, on the Cumbria...             25   \n",
       "279621     animate or inanimate, have a spirit or \"etiäi...             26   \n",
       "287229     function theorem states that for every real-v...             26   \n",
       "26712375   and illustrated by Maki Fujii. The series fol...             26   \n",
       "38894426   29, 1973) is an American former professional ...             28   \n",
       "\n",
       "          generated_text_tokens    random  \\\n",
       "id                                          \n",
       "63064638                     88  0.170068   \n",
       "279621                      101  0.839452   \n",
       "287229                       65  0.532203   \n",
       "26712375                    150  0.715507   \n",
       "38894426                    162  0.395063   \n",
       "\n",
       "                                                       text      label  \n",
       "id                                                                      \n",
       "63064638  Sexhow railway station was a railway station l...  generated  \n",
       "279621    In Finnish folklore, all places and things, an...       wiki  \n",
       "287229    In mathematics, specifically differential calc...       wiki  \n",
       "26712375  is a Japanese shōjo manga series written and i...       wiki  \n",
       "38894426  Robert Milner \"Rob\" Bradley, Jr. (born August ...  generated  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data = os.path.join(os.path.dirname(os.path.abspath(os.path.curdir)),'raw_data')\n",
    "if 'data.csv' in os.listdir(path_data):\n",
    "    print('loading local')\n",
    "    df = pd.read_csv(path_data+'/data.csv',index_col='id')\n",
    "else:\n",
    "    df = get_ds()\n",
    "    df.set_index('id',inplace=True)\n",
    "    df['random']=np.random.random(len(df))\n",
    "    \n",
    "    # reorganize ds and randomize samples wiki/generated\n",
    "    df.loc[df['random']<.5,'text']=df['generated_intro']\n",
    "    df.loc[df['random']<.5,'label']='generated'\n",
    "    df.loc[df['random']>=.5,'text']=df['wiki_intro']\n",
    "    df.loc[df['random']>=.5,'label']='wiki'\n",
    "    df.to_csv('../raw_data/data.csv')\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "864b45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check distribution is similar accross classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c9f560c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_len</th>\n",
       "      <th>wiki_intro_len</th>\n",
       "      <th>generated_intro_len</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>generated_text_tokens</th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>74978.000000</td>\n",
       "      <td>74978.000000</td>\n",
       "      <td>74978.000000</td>\n",
       "      <td>74978.000000</td>\n",
       "      <td>74978.000000</td>\n",
       "      <td>74978.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.213689</td>\n",
       "      <td>196.078716</td>\n",
       "      <td>129.492865</td>\n",
       "      <td>28.938182</td>\n",
       "      <td>165.734816</td>\n",
       "      <td>0.251266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.627942</td>\n",
       "      <td>41.496280</td>\n",
       "      <td>57.087880</td>\n",
       "      <td>5.056070</td>\n",
       "      <td>77.239233</td>\n",
       "      <td>0.144518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>0.125750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>0.251661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>0.376973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.499997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          title_len  wiki_intro_len  generated_intro_len  prompt_tokens  \\\n",
       "count  74978.000000    74978.000000         74978.000000   74978.000000   \n",
       "mean       2.213689      196.078716           129.492865      28.938182   \n",
       "std        0.627942       41.496280            57.087880       5.056070   \n",
       "min        1.000000      150.000000             7.000000      21.000000   \n",
       "25%        2.000000      164.000000            86.000000      26.000000   \n",
       "50%        2.000000      184.000000           122.000000      28.000000   \n",
       "75%        3.000000      216.000000           170.000000      31.000000   \n",
       "max        3.000000      350.000000           278.000000     148.000000   \n",
       "\n",
       "       generated_text_tokens        random  \n",
       "count           74978.000000  74978.000000  \n",
       "mean              165.734816      0.251266  \n",
       "std                77.239233      0.144518  \n",
       "min                 2.000000      0.000007  \n",
       "25%               107.000000      0.125750  \n",
       "50%               155.000000      0.251661  \n",
       "75%               220.000000      0.376973  \n",
       "max               300.000000      0.499997  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']=='generated'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b250b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_len</th>\n",
       "      <th>wiki_intro_len</th>\n",
       "      <th>generated_intro_len</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>generated_text_tokens</th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>75022.00000</td>\n",
       "      <td>75022.000000</td>\n",
       "      <td>75022.000000</td>\n",
       "      <td>75022.000000</td>\n",
       "      <td>75022.000000</td>\n",
       "      <td>75022.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.21707</td>\n",
       "      <td>195.931553</td>\n",
       "      <td>129.445443</td>\n",
       "      <td>28.977327</td>\n",
       "      <td>165.746688</td>\n",
       "      <td>0.749451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.63108</td>\n",
       "      <td>41.392367</td>\n",
       "      <td>56.993277</td>\n",
       "      <td>5.033946</td>\n",
       "      <td>77.203830</td>\n",
       "      <td>0.144789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>0.624155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>0.749220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.00000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>0.875147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.00000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title_len  wiki_intro_len  generated_intro_len  prompt_tokens  \\\n",
       "count  75022.00000    75022.000000         75022.000000   75022.000000   \n",
       "mean       2.21707      195.931553           129.445443      28.977327   \n",
       "std        0.63108       41.392367            56.993277       5.033946   \n",
       "min        1.00000      150.000000             7.000000      21.000000   \n",
       "25%        2.00000      164.000000            86.000000      26.000000   \n",
       "50%        2.00000      184.000000           122.000000      28.000000   \n",
       "75%        3.00000      216.000000           170.000000      31.000000   \n",
       "max        3.00000      350.000000           276.000000     116.000000   \n",
       "\n",
       "       generated_text_tokens        random  \n",
       "count           75022.000000  75022.000000  \n",
       "mean              165.746688      0.749451  \n",
       "std                77.203830      0.144789  \n",
       "min                 1.000000      0.500001  \n",
       "25%               107.000000      0.624155  \n",
       "50%               155.000000      0.749220  \n",
       "75%               220.000000      0.875147  \n",
       "max               300.000000      0.999985  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']=='wiki'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cce15201",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df['text'],df['label'],test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c4739d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1469885          wiki\n",
       "44944148    generated\n",
       "39308925    generated\n",
       "31136511    generated\n",
       "46435501         wiki\n",
       "              ...    \n",
       "61569845    generated\n",
       "58861615         wiki\n",
       "51499312         wiki\n",
       "17334432    generated\n",
       "10064792         wiki\n",
       "Name: label, Length: 120000, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e43d57",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4a4eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize text ; using tfidf\n",
    "vectorize = TfidfVectorizer(ngram_range=(1,1),max_df=.95,min_df=.05)\n",
    "\n",
    "#transform\n",
    "X_train_vect = vectorize.fit_transform(X_train)\n",
    "X_test_vect = vectorize.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0736160a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 213)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe480c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b87d80f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7454"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy of NB model\n",
    "model.score(X_test_vect,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7693e3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   generated       0.72      0.76      0.74     14389\n",
      "        wiki       0.77      0.73      0.75     15611\n",
      "\n",
      "    accuracy                           0.75     30000\n",
      "   macro avg       0.75      0.75      0.75     30000\n",
      "weighted avg       0.75      0.75      0.75     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report \n",
    "y_pred = model.predict(X_test_vect)\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ead2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    X_train_vect = X_train_vect.toarray()\n",
    "    X_test_vect = X_test_vect.toarray()\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "if len(X_train_vect.shape)<3:\n",
    "    X_train_vect = np.expand_dims(X_train_vect,-1)\n",
    "    X_test_vect = np.expand_dims(X_test_vect,-1)\n",
    "\n",
    "y_train = np.where(y_train=='generated',1,0)\n",
    "y_test = np.where(y_test=='generated',1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbca7034",
   "metadata": {},
   "source": [
    "# Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ecefc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252084d",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff7f7b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20d701e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def lstm_model():\n",
    "    inputs = tf.keras.layers.Input(shape=(X_train_vect[0].shape))\n",
    "#     inputs = tf.keras.layers.Input(shape=(200,1))\n",
    "#     x = tf.keras.layers.LSTM(128,return_sequences=True,activation='tanh')(inputs)\n",
    "    x = tf.keras.layers.LSTM(32,return_sequences=False,activation='tanh')(inputs)\n",
    "    x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs,outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "811f5e5d",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compile\n",
    "lstm = lstm_model()\n",
    "lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bccd1035",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#callbacks\n",
    "\n",
    "#early stopping\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=4,restore_best_weights=True)\n",
    "\n",
    "#tensorboard\n",
    "log_dir = os.path.join(os.path.abspath(os.path.pardir),'logs','simple_lstm')\n",
    "tb = tf.keras.callbacks.TensorBoard(log_dir=log_dir,write_graph=False,)\n",
    "\n",
    "#learning rate\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=.5,patience=3,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7b3519",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3000/3000 [==============================] - 167s 56ms/step - loss: 0.5606 - accuracy: 0.7086 - val_loss: 0.5541 - val_accuracy: 0.7103 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "3000/3000 [==============================] - 168s 56ms/step - loss: 0.5544 - accuracy: 0.7125 - val_loss: 0.5461 - val_accuracy: 0.7162 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "3000/3000 [==============================] - 168s 56ms/step - loss: 0.5470 - accuracy: 0.7179 - val_loss: 0.5421 - val_accuracy: 0.7186 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "3000/3000 [==============================] - 168s 56ms/step - loss: 0.5436 - accuracy: 0.7224 - val_loss: 0.5391 - val_accuracy: 0.7205 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "3000/3000 [==============================] - 169s 56ms/step - loss: 0.5373 - accuracy: 0.7265 - val_loss: 0.5257 - val_accuracy: 0.7348 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "3000/3000 [==============================] - 171s 57ms/step - loss: 0.5345 - accuracy: 0.7293 - val_loss: 0.5228 - val_accuracy: 0.7350 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "3000/3000 [==============================] - 172s 57ms/step - loss: 0.5285 - accuracy: 0.7342 - val_loss: 0.5238 - val_accuracy: 0.7363 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "3000/3000 [==============================] - 172s 57ms/step - loss: 0.5244 - accuracy: 0.7389 - val_loss: 0.5249 - val_accuracy: 0.7445 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "3000/3000 [==============================] - 171s 57ms/step - loss: 0.5192 - accuracy: 0.7417 - val_loss: 0.5075 - val_accuracy: 0.7471 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "3000/3000 [==============================] - 171s 57ms/step - loss: 0.5142 - accuracy: 0.7472 - val_loss: 0.5043 - val_accuracy: 0.7477 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "3000/3000 [==============================] - 178s 59ms/step - loss: 0.5089 - accuracy: 0.7527 - val_loss: 0.5039 - val_accuracy: 0.7508 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "3000/3000 [==============================] - 174s 58ms/step - loss: 0.5029 - accuracy: 0.7555 - val_loss: 0.4917 - val_accuracy: 0.7595 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "3000/3000 [==============================] - 173s 58ms/step - loss: 0.4978 - accuracy: 0.7607 - val_loss: 0.4929 - val_accuracy: 0.7607 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "3000/3000 [==============================] - 172s 57ms/step - loss: 0.4931 - accuracy: 0.7646 - val_loss: 0.4795 - val_accuracy: 0.7676 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "3000/3000 [==============================] - 171s 57ms/step - loss: 0.4872 - accuracy: 0.7671 - val_loss: 0.5004 - val_accuracy: 0.7572 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "3000/3000 [==============================] - 172s 57ms/step - loss: 0.4827 - accuracy: 0.7711 - val_loss: 0.4739 - val_accuracy: 0.7782 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "3000/3000 [==============================] - 176s 59ms/step - loss: 0.4787 - accuracy: 0.7727 - val_loss: 0.4685 - val_accuracy: 0.7752 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "3000/3000 [==============================] - 178s 59ms/step - loss: 0.4753 - accuracy: 0.7754 - val_loss: 0.4632 - val_accuracy: 0.7811 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "3000/3000 [==============================] - 178s 59ms/step - loss: 0.4707 - accuracy: 0.7787 - val_loss: 0.4806 - val_accuracy: 0.7765 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "3000/3000 [==============================] - 176s 59ms/step - loss: 0.4678 - accuracy: 0.7797 - val_loss: 0.4591 - val_accuracy: 0.7816 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "3000/3000 [==============================] - 175s 58ms/step - loss: 0.4645 - accuracy: 0.7828 - val_loss: 0.4661 - val_accuracy: 0.7812 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "3000/3000 [==============================] - 176s 59ms/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4586 - val_accuracy: 0.7822 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "1298/3000 [===========>..................] - ETA: 1:27 - loss: 0.4588 - accuracy: 0.7870"
     ]
    }
   ],
   "source": [
    "history = lstm.fit(x=X_train_vect,\n",
    "                   y=np.expand_dims(y_train,-1),\n",
    "                   validation_split=.2,\n",
    "                   callbacks=[es,tb,lr],\n",
    "                   batch_size=32,\n",
    "                   epochs=50,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68ec7d5b",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/arthurcollard/code/arthurcol/gpt_vs_human/models/simple_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/arthurcollard/code/arthurcol/gpt_vs_human/models/simple_lstm/assets\n"
     ]
    }
   ],
   "source": [
    "lstm.save(os.path.join(os.path.abspath(os.path.pardir),'models','simple_lstm'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e14dc",
   "metadata": {},
   "source": [
    "## Using Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d99c1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilstm_model():\n",
    "    inputs = tf.keras.layers.Input(shape=(X_train_vect[0].shape))\n",
    "#     inputs = tf.keras.layers.Input(shape=(200,1))\n",
    "#     x = tf.keras.layers.LSTM(128,return_sequences=True,activation='tanh')(inputs)\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,return_sequences=False,activation='tanh'))(inputs)\n",
    "    x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs,outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a686a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile\n",
    "bilstm = bilstm_model()\n",
    "bilstm.compile(loss='binary_crossentropy',optimizer='adam',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b00ef11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks\n",
    "\n",
    "model_name='bi_lstm_2'\n",
    "\n",
    "#early stopping\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=3,restore_best_weights=True)\n",
    "\n",
    "#tensorboard\n",
    "log_dir = os.path.join(os.path.abspath(os.path.pardir),'logs',model_name)\n",
    "tb = tf.keras.callbacks.TensorBoard(log_dir=log_dir,write_graph=False,)\n",
    "\n",
    "#learning rate\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=.5,patience=2,verbose=1)\n",
    "\n",
    "#model checkpoint\n",
    "model_path = os.path.join(os.path.abspath(os.path.pardir),'models',model_name)\n",
    "mc = tf.keras.callbacks.ModelCheckpoint(filepath=model_path,\n",
    "                                        monitor='val_accuracy',\n",
    "                                        verbose=1,\n",
    "                                        save_best_only=True,\n",
    "                                        save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9771b69c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 12:43:10.165371: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-23 12:43:10.333292: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-23 12:43:10.333407: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-23 12:43:10.926542: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-23 12:43:10.940076: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6475 - accuracy: 0.6240"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 12:45:28.739470: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-23 12:45:28.803788: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-23 12:45:28.803829: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 161s 105ms/step - loss: 0.6475 - accuracy: 0.6240 - val_loss: 0.6132 - val_accuracy: 0.6732 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 157s 105ms/step - loss: 0.6183 - accuracy: 0.6631 - val_loss: 0.6061 - val_accuracy: 0.6758 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 155s 103ms/step - loss: 0.6020 - accuracy: 0.6770 - val_loss: 0.5903 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 156s 104ms/step - loss: 0.5899 - accuracy: 0.6893 - val_loss: 0.5965 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 158s 105ms/step - loss: 0.5707 - accuracy: 0.7059 - val_loss: 0.5755 - val_accuracy: 0.7003 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 158s 105ms/step - loss: 0.5617 - accuracy: 0.7134 - val_loss: 0.5519 - val_accuracy: 0.7175 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 159s 106ms/step - loss: 0.5555 - accuracy: 0.7178 - val_loss: 0.5834 - val_accuracy: 0.6928 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 153s 102ms/step - loss: 0.5503 - accuracy: 0.7220 - val_loss: 0.5446 - val_accuracy: 0.7241 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 155s 103ms/step - loss: 0.5416 - accuracy: 0.7272 - val_loss: 0.5333 - val_accuracy: 0.7322 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 162s 108ms/step - loss: 0.5354 - accuracy: 0.7321 - val_loss: 0.5242 - val_accuracy: 0.7403 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 157s 105ms/step - loss: 0.5259 - accuracy: 0.7390 - val_loss: 0.5337 - val_accuracy: 0.7350 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 156s 104ms/step - loss: 0.5179 - accuracy: 0.7441 - val_loss: 0.5084 - val_accuracy: 0.7474 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 158s 105ms/step - loss: 0.5131 - accuracy: 0.7472 - val_loss: 0.5191 - val_accuracy: 0.7426 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 158s 105ms/step - loss: 0.5040 - accuracy: 0.7554 - val_loss: 0.5026 - val_accuracy: 0.7529 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 159s 106ms/step - loss: 0.4992 - accuracy: 0.7578 - val_loss: 0.4932 - val_accuracy: 0.7609 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 161s 107ms/step - loss: 0.4922 - accuracy: 0.7630 - val_loss: 0.4893 - val_accuracy: 0.7632 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 162s 108ms/step - loss: 0.4892 - accuracy: 0.7650 - val_loss: 0.4947 - val_accuracy: 0.7594 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 162s 108ms/step - loss: 0.4862 - accuracy: 0.7671 - val_loss: 0.4889 - val_accuracy: 0.7645 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 163s 109ms/step - loss: 0.4808 - accuracy: 0.7705 - val_loss: 0.4851 - val_accuracy: 0.7670 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 164s 109ms/step - loss: 0.4784 - accuracy: 0.7723 - val_loss: 0.4710 - val_accuracy: 0.7746 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 165s 110ms/step - loss: 0.4748 - accuracy: 0.7746 - val_loss: 0.4752 - val_accuracy: 0.7709 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4721 - accuracy: 0.7765\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1500/1500 [==============================] - 165s 110ms/step - loss: 0.4721 - accuracy: 0.7765 - val_loss: 0.4739 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 166s 111ms/step - loss: 0.4605 - accuracy: 0.7847 - val_loss: 0.4734 - val_accuracy: 0.7712 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = bilstm.fit(x=X_train_vect,\n",
    "                   y=np.expand_dims(y_train,-1),\n",
    "                   validation_split=.2,\n",
    "                   callbacks=[es,tb,lr],\n",
    "                   batch_size=64,\n",
    "                   epochs=50,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c86d6638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3746fe3",
   "metadata": {},
   "source": [
    "## Unleash the power of attention models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e58a1463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61a875bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 317kB/s]\n",
      "Downloading (…)\"tf_model.h5\";: 100%|██████████| 536M/536M [02:28<00:00, 3.61MB/s] \n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "21162c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 702kB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "86d14bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.3 s, sys: 4.15 s, total: 1min 2s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lengths = [len(x.split()) for x in X_train]\n",
    "tokens_raw = tokenizer(list(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7f98c9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x5b8fdd750>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get lengths\n",
    "lengths = [len(x) for x in tokens_raw.input_ids]\n",
    "#check distribution of lengths of tokens\n",
    "plt.hist(lengths,bins=30);\n",
    "plt.vlines(x=256,ymin=0,ymax=30000,color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "67d6c790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.93% of texts contains less than 256 tokens (not words!)\n"
     ]
    }
   ],
   "source": [
    "## check proportion\n",
    "_ = sum(len(el) <= 256 for el in tokens_raw.input_ids)/len(tokens_raw.input_ids)*100\n",
    "\n",
    "print(f'{_:.2f}% of texts contains less than 256 tokens (not words!)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "19b9a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens with truncation and padding \n",
    "tokens_train = tokenizer(list(X_train),padding='max_length',max_length=256,truncation=True)\n",
    "tokens_test = tokenizer(list(X_test),padding='max_length',max_length=256,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a96ad1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bertmodel():\n",
    "    input_ids = tf.keras.layers.Input(shape=(256),dtype=tf.int32,name='input_ids')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(256),dtype=tf.int32,name='attention_mask')\n",
    "    \n",
    "    backbone = TFBertModel.from_pretrained('bert-base-uncased',)\n",
    "    pooler_output = backbone(input_ids,attention_mask)['pooler_output']\n",
    "    backbone.trainable = False\n",
    "    \n",
    "    x = tf.keras.layers.Dense(128,activation='relu')(pooler_output)\n",
    "    output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=(input_ids,attention_mask),outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "006eec5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#compile\n",
    "bertmodel = init_bertmodel()\n",
    "bertmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "eb4661b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks\n",
    "\n",
    "model_name='bertmodel'\n",
    "\n",
    "#early stopping\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=3,restore_best_weights=True)\n",
    "\n",
    "#tensorboard\n",
    "log_dir = os.path.join(os.path.abspath(os.path.pardir),'logs',model_name)\n",
    "tb = tf.keras.callbacks.TensorBoard(log_dir=log_dir,write_graph=False,)\n",
    "\n",
    "#learning rate\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=.5,patience=2,verbose=1)\n",
    "\n",
    "#model checkpoint\n",
    "model_path = os.path.join(os.path.abspath(os.path.pardir),'models',model_name)\n",
    "mc = tf.keras.callbacks.ModelCheckpoint(filepath=model_path,\n",
    "                                        monitor='val_accuracy',\n",
    "                                        verbose=1,\n",
    "                                        save_best_only=True,\n",
    "                                        save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ef446",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 15:56:38.939972: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 154/1500 [==>...........................] - ETA: 37:36 - loss: 0.4893 - accuracy: 0.7612"
     ]
    }
   ],
   "source": [
    "history = bertmodel.fit(x={\n",
    "    'input_ids':np.array(tokens_train.input_ids),\n",
    "    'attention_mask':np.array(tokens_train.attention_mask)},\n",
    "                   y=np.expand_dims(y_train,-1),\n",
    "                   validation_split=.2,\n",
    "                   callbacks=[es,tb,lr],\n",
    "                   batch_size=64,\n",
    "                   epochs=50,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda17dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
